{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = os.path.abspath(os.path.join('../'))\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "from utils.load_data import load_fer2013, parse_fer2013, \\\n",
    "                            load_CKPlus, fer_csv_to_png\n",
    "from utils.preprocess import resnet_preprocess\n",
    "from utils.generators import init_resnet_generator, init_cnn_generator\n",
    "from utils.plots import plot_model_history\n",
    "from models.build import build_resnet_model, build_cnn_baseline_model\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_csv(data_dir='../data/fer', file_path='../data/fer2013/fer2013.csv'):\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "        os.mkdir(data_dir + '/train')\n",
    "        os.mkdir(data_dir + '/val')\n",
    "        os.mkdir(data_dir + '/test')\n",
    "        fer_csv_to_png(file_path=file_path,\n",
    "                       data_dir=data_dir)\n",
    "\n",
    "# Local\n",
    "unpack_csv(data_dir='../data/fer', file_path='../data/fer2013/fer2013.csv')\n",
    "# Google colab\n",
    "# unpack_csv(data_dir='/fer', file_path='/content/drive/MyDrive/fer2013.csv')\n",
    "\n",
    "train_data, val_data, test_data = load_fer2013('../data/fer2013/fer2013.csv')\n",
    "X_train, Y_train = parse_fer2013(train_data)\n",
    "X_val, Y_val = parse_fer2013(val_data)\n",
    "X_test, Y_test = parse_fer2013(test_data)\n",
    "X_test = resnet_preprocess(X_test, target_size=(197, 197), target_channels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 28709\n",
    "num_val = 3589\n",
    "batch_size = 128\n",
    "num_epochs = 150\n",
    "patience = 20\n",
    "saved_models_path = '../models/saved_models/'\n",
    "dataset_name = 'fer2013'\n",
    "model_name = '_resnet50_1'\n",
    "history_name = '_hist' + model_name\n",
    "\n",
    "# ../models/saved_models/fer2013_resnet50_1\n",
    "model_path = saved_models_path + dataset_name + model_name\n",
    "\n",
    "# ../models/saved_models/fer2013_hist_resnet50_1\n",
    "history_path = saved_models_path + dataset_name + history_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = init_resnet_generator(data_dir='../data/fer/train', with_aug=True)\n",
    "val_gen = init_resnet_generator(data_dir='../data/fer/val', with_aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_path = model_path + '.hdf5'\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "model_checkpoint = ModelCheckpoint(cpt_path, save_best_only=True)\n",
    "callbacks = [model_checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/Tensorflow-gpu/lib/python3.7/site-packages/tensorflow/python/keras/mixed_precision/loss_scale.py:56: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.global_policy()\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vggface_resnet50 (Functional (None, 1, 1, 2048)        23561152  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 36,156,359\n",
      "Trainable params: 12,648,327\n",
      "Non-trainable params: 23,508,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_resnet_model()\n",
    "opt = tensorflow.keras.optimizers.Adam(0.001)\n",
    "opt_mixed_precision = keras.mixed_precision.LossScaleOptimizer(opt)\n",
    "model.compile(optimizer=opt_mixed_precision, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/Tensorflow-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "224/224 [==============================] - 102s 291ms/step - loss: 3.7218 - accuracy: 0.3133 - val_loss: 1.9140 - val_accuracy: 0.1691\n",
      "Epoch 2/150\n",
      "224/224 [==============================] - 51s 219ms/step - loss: 1.2266 - accuracy: 0.5389 - val_loss: 1.9690 - val_accuracy: 0.1702\n",
      "Epoch 3/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 1.1192 - accuracy: 0.5900 - val_loss: 1.3792 - val_accuracy: 0.4665\n",
      "Epoch 4/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 1.0510 - accuracy: 0.6094 - val_loss: 0.9923 - val_accuracy: 0.6253\n",
      "Epoch 5/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 1.0126 - accuracy: 0.6184 - val_loss: 0.9500 - val_accuracy: 0.6443\n",
      "Epoch 6/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.9899 - accuracy: 0.6296 - val_loss: 0.9506 - val_accuracy: 0.6445\n",
      "Epoch 7/150\n",
      "224/224 [==============================] - 51s 221ms/step - loss: 0.9560 - accuracy: 0.6405 - val_loss: 0.9479 - val_accuracy: 0.6549\n",
      "Epoch 8/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.9326 - accuracy: 0.6557 - val_loss: 0.9251 - val_accuracy: 0.6624\n",
      "Epoch 9/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.9180 - accuracy: 0.6584 - val_loss: 0.9243 - val_accuracy: 0.6635\n",
      "Epoch 10/150\n",
      "224/224 [==============================] - 51s 218ms/step - loss: 0.8883 - accuracy: 0.6694 - val_loss: 0.9292 - val_accuracy: 0.6616\n",
      "Epoch 11/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.8808 - accuracy: 0.6731 - val_loss: 0.8985 - val_accuracy: 0.6763\n",
      "Epoch 12/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.8770 - accuracy: 0.6688 - val_loss: 0.8895 - val_accuracy: 0.6727\n",
      "Epoch 13/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.8565 - accuracy: 0.6827 - val_loss: 0.8900 - val_accuracy: 0.6802\n",
      "Epoch 14/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.8256 - accuracy: 0.6898 - val_loss: 0.8776 - val_accuracy: 0.6791\n",
      "Epoch 15/150\n",
      "224/224 [==============================] - 49s 214ms/step - loss: 0.8304 - accuracy: 0.6878 - val_loss: 0.9161 - val_accuracy: 0.6710\n",
      "Epoch 16/150\n",
      "224/224 [==============================] - 49s 214ms/step - loss: 0.8162 - accuracy: 0.6937 - val_loss: 0.8729 - val_accuracy: 0.6802\n",
      "Epoch 17/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 0.7901 - accuracy: 0.7023 - val_loss: 0.8576 - val_accuracy: 0.6936\n",
      "Epoch 18/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 0.7641 - accuracy: 0.7103 - val_loss: 0.8698 - val_accuracy: 0.6922\n",
      "Epoch 19/150\n",
      "224/224 [==============================] - 49s 215ms/step - loss: 0.7661 - accuracy: 0.7157 - val_loss: 0.8650 - val_accuracy: 0.7012\n",
      "Epoch 20/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.7550 - accuracy: 0.7195 - val_loss: 0.8511 - val_accuracy: 0.7001\n",
      "Epoch 21/150\n",
      "224/224 [==============================] - 48s 209ms/step - loss: 0.7392 - accuracy: 0.7191 - val_loss: 0.8504 - val_accuracy: 0.7034\n",
      "Epoch 22/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.7385 - accuracy: 0.7227 - val_loss: 0.8610 - val_accuracy: 0.6995\n",
      "Epoch 23/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.7233 - accuracy: 0.7278 - val_loss: 0.8488 - val_accuracy: 0.7023\n",
      "Epoch 24/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 0.7077 - accuracy: 0.7329 - val_loss: 0.8452 - val_accuracy: 0.6950\n",
      "Epoch 25/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 0.6930 - accuracy: 0.7381 - val_loss: 0.8468 - val_accuracy: 0.7031\n",
      "Epoch 26/150\n",
      "224/224 [==============================] - 49s 210ms/step - loss: 0.6861 - accuracy: 0.7443 - val_loss: 0.8339 - val_accuracy: 0.7001\n",
      "Epoch 27/150\n",
      "224/224 [==============================] - 51s 220ms/step - loss: 0.6721 - accuracy: 0.7467 - val_loss: 0.8518 - val_accuracy: 0.7065\n",
      "Epoch 28/150\n",
      "224/224 [==============================] - 50s 216ms/step - loss: 0.6698 - accuracy: 0.7466 - val_loss: 0.8489 - val_accuracy: 0.7059\n",
      "Epoch 29/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.6581 - accuracy: 0.7533 - val_loss: 0.8368 - val_accuracy: 0.7070\n",
      "Epoch 30/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.6348 - accuracy: 0.7649 - val_loss: 0.8338 - val_accuracy: 0.7171\n",
      "Epoch 31/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.6284 - accuracy: 0.7601 - val_loss: 0.8358 - val_accuracy: 0.7104\n",
      "Epoch 32/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.6156 - accuracy: 0.7687 - val_loss: 0.8333 - val_accuracy: 0.7157\n",
      "Epoch 33/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.5958 - accuracy: 0.7755 - val_loss: 0.8521 - val_accuracy: 0.7162\n",
      "Epoch 34/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.5890 - accuracy: 0.7808 - val_loss: 0.8393 - val_accuracy: 0.7165\n",
      "Epoch 35/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.5815 - accuracy: 0.7859 - val_loss: 0.8463 - val_accuracy: 0.7182\n",
      "Epoch 36/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.5741 - accuracy: 0.7869 - val_loss: 0.8433 - val_accuracy: 0.7199\n",
      "Epoch 37/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.5748 - accuracy: 0.7874 - val_loss: 0.8589 - val_accuracy: 0.7143\n",
      "Epoch 38/150\n",
      "224/224 [==============================] - 50s 214ms/step - loss: 0.5613 - accuracy: 0.7954 - val_loss: 0.8434 - val_accuracy: 0.7165\n",
      "Epoch 39/150\n",
      "224/224 [==============================] - 49s 212ms/step - loss: 0.5575 - accuracy: 0.7941 - val_loss: 0.8516 - val_accuracy: 0.7188\n",
      "Epoch 40/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.5413 - accuracy: 0.8015 - val_loss: 0.8474 - val_accuracy: 0.7193\n",
      "Epoch 41/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.5336 - accuracy: 0.8030 - val_loss: 0.8413 - val_accuracy: 0.7204\n",
      "Epoch 42/150\n",
      "224/224 [==============================] - 51s 220ms/step - loss: 0.5251 - accuracy: 0.8076 - val_loss: 0.8386 - val_accuracy: 0.7243\n",
      "Epoch 43/150\n",
      "224/224 [==============================] - 51s 221ms/step - loss: 0.5118 - accuracy: 0.8124 - val_loss: 0.8523 - val_accuracy: 0.7185\n",
      "Epoch 44/150\n",
      "224/224 [==============================] - 49s 211ms/step - loss: 0.5094 - accuracy: 0.8129 - val_loss: 0.8575 - val_accuracy: 0.7154\n",
      "Epoch 45/150\n",
      "224/224 [==============================] - 49s 214ms/step - loss: 0.4932 - accuracy: 0.8209 - val_loss: 0.8436 - val_accuracy: 0.7182\n",
      "Epoch 46/150\n",
      "224/224 [==============================] - 50s 213ms/step - loss: 0.4919 - accuracy: 0.8215 - val_loss: 0.8469 - val_accuracy: 0.7224\n",
      "Epoch 47/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.4956 - accuracy: 0.8201 - val_loss: 0.8547 - val_accuracy: 0.7201\n",
      "Epoch 48/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.4833 - accuracy: 0.8203 - val_loss: 0.8536 - val_accuracy: 0.7190\n",
      "Epoch 49/150\n",
      "224/224 [==============================] - 50s 215ms/step - loss: 0.4649 - accuracy: 0.8298 - val_loss: 0.8629 - val_accuracy: 0.7227\n",
      "Epoch 50/150\n",
      "224/224 [==============================] - 50s 214ms/step - loss: 0.4506 - accuracy: 0.8319 - val_loss: 0.8684 - val_accuracy: 0.7165\n",
      "Epoch 51/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.4517 - accuracy: 0.8383 - val_loss: 0.8660 - val_accuracy: 0.7165\n",
      "Epoch 52/150\n",
      "224/224 [==============================] - 49s 213ms/step - loss: 0.4509 - accuracy: 0.8353 - val_loss: 0.8715 - val_accuracy: 0.7229\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs=num_epochs,\n",
    "                    steps_per_epoch=len(X_train)//batch_size,\n",
    "                    validation_steps=len(X_val)//batch_size,\n",
    "                    callbacks=callbacks, workers=10, verbose=1, max_queue_size=100)\n",
    "\n",
    "# Saving final model and history\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "cnt_epoch = len(history.history['val_accuracy'])\n",
    "np.save(f'{history_path}-e{cnt_epoch:02d}-a{val_acc:.2f}.npy', history.history)\n",
    "model.save(f'{model_path}-e{cnt_epoch:02d}-a{val_acc:.2f}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load\n",
    "# history = np.load(history_path + '-e03-a0.41.npy', allow_pickle=True)\n",
    "# history = history.item()\n",
    "# model = load_model(model_path + '-e41-a0.71.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 31s 143ms/step - loss: 0.8113 - accuracy: 0.7236\n",
      "Model accuracy: 72.36%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(histroy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1453b2ee3828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/Facial-Expression-Recognition/utils/plots.py\u001b[0m in \u001b[0;36mplot_model_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plot_model_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
